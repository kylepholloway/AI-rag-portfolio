import { PrismaClient } from "@prisma/client";
import OpenAI from "openai";
import type { NextApiRequest, NextApiResponse } from "next";

const prisma = new PrismaClient();
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY as string,
});

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== "POST") {
    console.error("‚ùå Request Method Not Allowed.");
    return res.status(405).json({ message: "Method Not Allowed" });
  }

  const { prompt } = req.body;

  if (!prompt) {
    console.error("‚ùå Request missing 'prompt' in body.");
    return res.status(400).json({ error: "Prompt is required." });
  }

  try {
    console.log("üîπ Received Prompt:", prompt);

    // Step 1: Generate an embedding for the user query
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: prompt,
    });

    console.log("üß† OpenAI Embedding Response:", JSON.stringify(embeddingResponse, null, 2));

    const embedding = embeddingResponse?.data?.[0]?.embedding ?? null;

    if (!embedding || !Array.isArray(embedding) || embedding.length !== 1536) {
      console.error("‚ùå OpenAI returned an invalid embedding:", embedding);
      return res.status(500).json({ error: "Invalid embedding generated by OpenAI." });
    }

    console.log("‚úÖ Embedding Before Query Execution:", embedding.length, "dimensions", embedding.slice(0, 5), "... (truncated)");

    // Step 2: Perform vector similarity search using the retrieved embedding
    let results: { title: string; content: string }[] = [];
    
    try {
      console.log("üîç Running Vector Search Query...");
      results = await prisma.$queryRawUnsafe<
        { title: string; content: string }[]
      >(
        `SELECT title, content FROM "KnowledgeBase" WHERE embedding IS NOT NULL ORDER BY embedding <-> CAST($1 AS vector) LIMIT 3`,
        embedding // ‚úÖ Fix: Explicitly cast to `vector`
      );

      console.log("‚úÖ Query Success! Found Results:", results.length);
    } catch (dbError) {
      console.error("‚ùå Database Query Failed:", dbError);
      return res.status(500).json({ error: "Database query failed." });
    }

    if (results.length === 0) {
      console.warn("‚ö†Ô∏è No Relevant Context Found in DB.");
      return res.status(200).json({ reply: "I'm sorry, I couldn't find relevant information in Kyle's portfolio." });
    }

    // Step 3: Format retrieved data into structured context
    const context = results
      .map((entry) => `Title: ${entry.title}\nContent: ${entry.content}`)
      .join("\n\n");

    console.log("üìÑ Retrieved Context for AI:", context);

    // Step 4: Pass retrieved context into OpenAI prompt
    console.log("ü§ñ Sending Context to GPT...");
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "You are an AI assistant helping answer questions about Kyle Holloway's career and expertise. Use the provided context when available." },
        { role: "system", content: `Context:\n${context}` },
        { role: "user", content: prompt }
      ],
    });

    console.log("‚úÖ OpenAI Response Received!");
    res.status(200).json({ reply: response.choices[0].message.content });

  } catch (error) {
    console.error("‚ùå General API Error:", error);
    res.status(500).json({ error: "An unexpected error occurred." });
  }
}
