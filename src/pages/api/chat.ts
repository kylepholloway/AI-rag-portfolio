import { PrismaClient } from "@prisma/client";
import OpenAI from "openai";
import type { NextApiRequest, NextApiResponse } from "next";

const prisma = new PrismaClient();
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY as string,
});

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== "POST") {
    console.error("‚ùå Request Method Not Allowed.");
    return res.status(405).json({ message: "Method Not Allowed" });
  }

  const { messages } = req.body;

  if (!messages || !Array.isArray(messages)) {
    console.error("‚ùå Request missing valid 'messages' array in body.");
    return res.status(400).json({ error: "Messages array is required." });
  }

  try {
    console.log("üîπ Received Messages:", messages);

    const userPrompt = messages[messages.length - 1]?.content;

    // Step 1: Generate an embedding for the latest user query
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: userPrompt,
    });

    const embedding = embeddingResponse?.data?.[0]?.embedding ?? null;
    if (!embedding || !Array.isArray(embedding) || embedding.length !== 1536) {
      console.error("‚ùå OpenAI returned an invalid embedding:", embedding);
      return res.status(500).json({ error: "Invalid embedding generated by OpenAI." });
    }

    console.log("‚úÖ Embedding Generated:", embedding.slice(0, 5), "... (truncated)");

    // Step 2: Perform vector similarity search using the retrieved embedding
    let results: { title: string; content: string }[] = [];

    try {
      console.log("üîç Running Vector Search Query...");
      results = await prisma.$queryRawUnsafe<
        { title: string; content: string }[]
      >(
        `SELECT title, content FROM "KnowledgeBase" WHERE embedding IS NOT NULL ORDER BY embedding <-> CAST($1 AS vector) LIMIT 3`,
        embedding
      );

      console.log("‚úÖ Query Success! Found Results:", results.length);
    } catch (dbError) {
      console.error("‚ùå Database Query Failed:", dbError);
      return res.status(500).json({ error: "Database query failed." });
    }

    const context = results
      .map((entry) => `Title: ${entry.title}\nContent: ${entry.content}`)
      .join("\n\n");

    console.log("üìÑ Retrieved Context for AI:", context);

    // Step 3: Pass full chat history & retrieved context to OpenAI
    console.log("ü§ñ Sending Full Conversation to GPT...");
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "You are an AI assistant helping answer questions about Kyle Holloway's career and expertise. Use the provided context when available." },
        { role: "system", content: `Context:\n${context}` },
        ...messages // ‚úÖ Use full chat history for context
      ],
    });

    console.log("‚úÖ OpenAI Response Received!");
    res.status(200).json({ reply: response.choices[0].message.content });

  } catch (error) {
    console.error("‚ùå General API Error:", error);
    res.status(500).json({ error: "An unexpected error occurred." });
  }
}
