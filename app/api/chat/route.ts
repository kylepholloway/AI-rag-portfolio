import { PrismaClient } from "@prisma/client";
import OpenAI from "openai";

const prisma = new PrismaClient();
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY as string,
});

// ‚úÖ New Next.js App Router syntax
export async function POST(req: Request) {
  try {
    const { messages, userId } = await req.json();

    if (!messages || !Array.isArray(messages)) {
      return new Response(JSON.stringify({ error: "Messages array is required." }), {
        status: 400,
        headers: { "Content-Type": "application/json" },
      });
    }

    console.log("üîπ Received Messages:", messages);

    const userPrompt = messages[messages.length - 1]?.content || "Unknown query";

    // ‚úÖ Step 1: Generate an embedding for the latest user query
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: userPrompt,
    });

    const embedding = embeddingResponse?.data?.[0]?.embedding ?? null;
    if (!embedding || !Array.isArray(embedding) || embedding.length !== 1536) {
      return new Response(JSON.stringify({ error: "Invalid embedding generated by OpenAI." }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    console.log("‚úÖ Embedding Generated:", embedding.slice(0, 5), "... (truncated)");

    // ‚úÖ Step 2: Perform vector similarity search using the retrieved embedding
    let results: { title: string; content: string }[] = [];

    try {
      console.log("üîç Running Vector Search Query...");
      results = await prisma.$queryRawUnsafe<{ title: string; content: string }[]>(
        `SELECT title, content FROM "KnowledgeBase" WHERE embedding IS NOT NULL ORDER BY embedding <-> CAST($1 AS vector) LIMIT 3`,
        embedding
      );
    } catch (dbError) {
      console.error("‚ùå Database Query Failed:", dbError);
      return new Response(JSON.stringify({ error: "Database query failed." }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    const context = results
      .map((entry) => `Title: ${entry.title}\nContent: ${entry.content}`)
      .join("\n\n");

    console.log("üìÑ Retrieved Context for AI:", context);

    // ‚úÖ Step 3: Pass full chat history & retrieved context to OpenAI
    console.log("ü§ñ Sending Full Conversation to GPT...");
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "You are an AI assistant helping answer questions about Kyle Holloway's career and expertise. Use the provided context when available." },
        { role: "system", content: `Context:\n${context}` },
        ...messages,
      ],
      user: userId, // ‚úÖ Tracks user messages in OpenAI dashboard
    });

    const aiResponse = response.choices[0].message.content ?? "No response received";

    // ‚úÖ Step 4: Store user queries & AI responses in your DB
    await prisma.userQueries.create({
      data: {
        query: userPrompt,
        response: aiResponse,
        createdAt: new Date(),
      },
    });

    console.log("‚úÖ Stored User Query & AI Response in DB");

    console.log("‚úÖ OpenAI Response Received!");
    return new Response(JSON.stringify({ reply: aiResponse }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });

  } catch (error) {
    console.error("‚ùå API Error:", error);
    return new Response(JSON.stringify({ error: "An unexpected error occurred." }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
